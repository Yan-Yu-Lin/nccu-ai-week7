# Part B éœ€æ±‚è¦æ ¼æ›¸

## å°ˆæ¡ˆç›®æ¨™

å»ºç«‹ RAG å¼·åŒ–çš„å…¬å¸å®¢æœå°è©±æ©Ÿå™¨äººï¼Œçµåˆï¼š
- FAISS å‘é‡è³‡æ–™åº«ï¼ˆPart A å·²å®Œæˆï¼‰
- Agentic searchï¼ˆAI å¯ä»¥åˆ—å‡ºæª”æ¡ˆã€è®€å–ç‰¹å®šæª”æ¡ˆï¼‰
- GPT-5 ç”Ÿæˆå›ç­”
- Gradio Web UI

---

## ä½¿ç”¨è€…æ„åœ–

### æ ¸å¿ƒéœ€æ±‚

1. **RAG å°è©±æ©Ÿå™¨äºº**
   - å¾ Google Drive ä¸‹è¼‰ `faiss_db.zip`
   - è¼‰å…¥ FAISS å‘é‡è³‡æ–™åº«
   - ä½¿ç”¨è€…å•å•é¡Œ â†’ æª¢ç´¢ç›¸é—œ chunks â†’ GPT-5 ç”Ÿæˆå›ç­”

2. **Agentic Searchï¼ˆé€²éšåŠŸèƒ½ï¼‰**
   - AI å¯ä»¥ã€Œåˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ Q&A æª”æ¡ˆã€ï¼ˆlist_files toolï¼‰
   - AI å¯ä»¥ã€Œè®€å–ç‰¹å®šæª”æ¡ˆçš„å…§å®¹ã€ï¼ˆread_file toolï¼‰
   - AI æœƒå…ˆæœå°‹æª”æ¡ˆæ¸…å–®ï¼Œæ±ºå®šè¦å¾å“ªäº›æª”æ¡ˆæª¢ç´¢ç­”æ¡ˆ
   - å±•ç¤ºã€ŒAI åœ¨æ€è€ƒè¦å»å“ªè£¡æ‰¾è³‡æ–™ã€çš„éç¨‹

3. **äººè¨­èˆ‡é¢¨æ ¼**
   - è§’è‰²ï¼šå…¬å¸å®¢æœåŠ©æ‰‹
   - èªæ°£ï¼šè¦ªåˆ‡ã€å°ˆæ¥­ã€æœ‰å¹«åŠ©
   - å›ç­”é¢¨æ ¼ï¼šç°¡æ½”æ˜ç­ï¼Œæä¾›å…·é«”æ­¥é©Ÿ
   - è‹¥è³‡æ–™ä¸è¶³ï¼šå»ºè­°è¯ç¹«çœŸäººå®¢æœ

---

## æŠ€è¡“æ¶æ§‹

### æª”æ¡ˆçµæ§‹ï¼ˆé æœŸï¼‰

```
Week7/
â”œâ”€â”€ rag_chatbot.py              # Part B ä¸»ç¨‹å¼
â”œâ”€â”€ faiss_db.zip                # Part A ç”¢å‡ºï¼ˆæˆ–å¾ Drive ä¸‹è¼‰ï¼‰
â”œâ”€â”€ faiss_db/                   # è§£å£“ç¸®å¾Œçš„è³‡æ–™åº«
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ metadata.json
â””â”€â”€ gradio_app.py               # ï¼ˆå¯é¸ï¼‰ç¨ç«‹çš„ Gradio UI
```

### æ ¸å¿ƒåŠŸèƒ½æ¨¡çµ„

#### 1. ç’°å¢ƒåµæ¸¬èˆ‡åˆå§‹åŒ–

```python
import os

def is_colab():
    """åµæ¸¬æ˜¯å¦åœ¨ Colab ç’°å¢ƒ"""
    try:
        import google.colab
        return True
    except:
        return False

def setup_environment():
    """è¨­å®š API key å’Œç’°å¢ƒ"""
    if is_colab():
        from google.colab import userdata
        api_key = userdata.get('OPENAI_API_KEY')
    else:
        api_key = os.getenv('OPENAI_API_KEY')  # æœ¬åœ°å¾ fish env

    return api_key
```

#### 2. ä¸‹è¼‰èˆ‡è¼‰å…¥å‘é‡è³‡æ–™åº«

```python
def download_faiss_db(gdrive_url):
    """å¾ Google Drive ä¸‹è¼‰ faiss_db.zip"""
    if is_colab():
        # Colab: ä½¿ç”¨ gdown
        !gdown --fuzzy -O faiss_db.zip "{gdrive_url}"
        !unzip -o faiss_db.zip
    else:
        # æœ¬åœ°ï¼šå‡è¨­å·²ç¶“å­˜åœ¨
        if not os.path.exists("faiss_db.zip"):
            print("æœ¬åœ°æ¨¡å¼ï¼šè«‹ç¢ºä¿ faiss_db.zip å­˜åœ¨")

def load_vectorstore():
    """è¼‰å…¥ FAISS å‘é‡è³‡æ–™åº«"""
    import faiss
    import json

    # è¼‰å…¥ FAISS index
    index = faiss.read_index("faiss_db/index.faiss")

    # è¼‰å…¥ metadata
    with open("faiss_db/metadata.json", 'r', encoding='utf-8') as f:
        metadata = json.load(f)

    return index, metadata
```

#### 3. RAG æª¢ç´¢ç³»çµ±

```python
def search_similar_chunks(query, index, metadata, embedding_model, k=5):
    """
    æœå°‹èˆ‡å•é¡Œæœ€ç›¸ä¼¼çš„ chunks

    Args:
        query: ä½¿ç”¨è€…å•é¡Œ
        index: FAISS index
        metadata: chunk metadata
        embedding_model: OpenAI embedding model
        k: å›å‚³å‰ k å€‹çµæœ

    Returns:
        List[Dict]: ç›¸é—œçš„ chunks
    """
    # 1. å°‡å•é¡Œè½‰æˆ embedding
    from openai import OpenAI
    client = OpenAI()

    response = client.embeddings.create(
        model="text-embedding-3-large",
        input=[query]
    )
    query_embedding = response.data[0].embedding

    # 2. FAISS æœå°‹
    import numpy as np
    query_vector = np.array([query_embedding]).astype('float32')
    distances, indices = index.search(query_vector, k)

    # 3. å–å¾—ç›¸é—œ chunks
    results = []
    for idx in indices[0]:
        if idx < len(metadata):
            results.append(metadata[idx])

    return results
```

#### 4. Agentic Search Toolsï¼ˆé€²éšåŠŸèƒ½ï¼‰

```python
def list_available_files(metadata):
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ä¾†æºæª”æ¡ˆ"""
    files = set(chunk["source_file"] for chunk in metadata)
    return list(files)

def read_file_chunks(filename, metadata):
    """è®€å–ç‰¹å®šæª”æ¡ˆçš„æ‰€æœ‰ chunks"""
    file_chunks = [
        chunk for chunk in metadata
        if chunk["source_file"] == filename
    ]
    return file_chunks

# å®šç¾© GPT-5 tools
AGENTIC_TOOLS = [
    {
        "type": "function",
        "name": "list_files",
        "description": "åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ Q&A ä¾†æºæª”æ¡ˆã€‚ç•¶ä½ éœ€è¦äº†è§£æœ‰å“ªäº›è³‡æ–™å¯ä»¥æŸ¥è©¢æ™‚ä½¿ç”¨ã€‚",
        "parameters": {
            "type": "object",
            "properties": {},
            "required": []
        }
    },
    {
        "type": "function",
        "name": "read_file",
        "description": "è®€å–ç‰¹å®šæª”æ¡ˆçš„å®Œæ•´å…§å®¹ã€‚ç•¶ä½ éœ€è¦æ·±å…¥äº†è§£æŸå€‹æª”æ¡ˆçš„è³‡è¨Šæ™‚ä½¿ç”¨ã€‚",
        "parameters": {
            "type": "object",
            "properties": {
                "filename": {
                    "type": "string",
                    "description": "è¦è®€å–çš„æª”æ¡ˆåç¨±ï¼Œä¾‹å¦‚ 'function calling.md'"
                }
            },
            "required": ["filename"]
        }
    },
    {
        "type": "function",
        "name": "search_chunks",
        "description": "åœ¨å‘é‡è³‡æ–™åº«ä¸­æœå°‹èˆ‡å•é¡Œç›¸é—œçš„å…§å®¹ç‰‡æ®µã€‚é€™æ˜¯ä¸»è¦çš„æœå°‹åŠŸèƒ½ã€‚",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "è¦æœå°‹çš„å•é¡Œæˆ–é—œéµå­—"
                },
                "k": {
                    "type": "number",
                    "description": "å›å‚³å‰ k å€‹æœ€ç›¸é—œçš„çµæœï¼Œé è¨­ 5"
                }
            },
            "required": ["query"]
        }
    }
]
```

#### 5. GPT-5 å°è©±ç”Ÿæˆ

```python
def generate_response(user_question, retrieved_chunks, chat_history=[]):
    """
    ä½¿ç”¨ GPT-5 ç”Ÿæˆå›ç­”

    Args:
        user_question: ä½¿ç”¨è€…å•é¡Œ
        retrieved_chunks: æª¢ç´¢åˆ°çš„ç›¸é—œ chunks
        chat_history: å°è©±æ­·å²ï¼ˆå¯é¸ï¼‰

    Returns:
        str: AI å›ç­”
    """
    from openai import OpenAI
    client = OpenAI()

    # çµ„åˆ context
    context = "\n\n".join([
        f"[ä¾†æºï¼š{chunk['source_file']}]\n{chunk['text']}"
        for chunk in retrieved_chunks
    ])

    # Prompt è¨­è¨ˆ
    system_prompt = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å…¬å¸å®¢æœåŠ©æ‰‹ã€‚
è«‹æ ¹æ“šæä¾›çš„è³‡æ–™ä¾†å›ç­”å®¢æˆ¶çš„å•é¡Œã€‚

å›ç­”é¢¨æ ¼ï¼š
- è¦ªåˆ‡ã€å°ˆæ¥­ã€æœ‰å¹«åŠ©
- ç°¡æ½”æ˜ç­ï¼Œæä¾›å…·é«”æ­¥é©Ÿ
- å¦‚æœè³‡æ–™ä¸­æ²’æœ‰ç­”æ¡ˆï¼Œèª å¯¦å‘ŠçŸ¥ä¸¦å»ºè­°è¯ç¹«çœŸäººå®¢æœ

è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼ˆå°ç£ï¼‰å›ç­”ã€‚"""

    user_prompt = f"""åƒè€ƒè³‡æ–™ï¼š
{context}

å®¢æˆ¶å•é¡Œï¼š{user_question}

è«‹æ ¹æ“šåƒè€ƒè³‡æ–™å›ç­”å®¢æˆ¶çš„å•é¡Œã€‚"""

    # å‘¼å« GPT-5
    response = client.responses.create(
        model="gpt-5",
        reasoning={"effort": "low"},  # å®¢æœå›ç­”éœ€è¦ä¸€å®šæ¨ç†èƒ½åŠ›
        instructions=system_prompt,
        input=[{"role": "user", "content": user_prompt}]
    )

    return response.output_text
```

#### 6. Gradio UI

```python
import gradio as gr

def chatbot_interface(message, history):
    """
    Gradio chatbot ä»‹é¢

    Args:
        message: ä½¿ç”¨è€…è¼¸å…¥
        history: å°è©±æ­·å²

    Returns:
        str: AI å›ç­”
    """
    # 1. æª¢ç´¢ç›¸é—œ chunks
    chunks = search_similar_chunks(message, index, metadata, k=5)

    # 2. ç”Ÿæˆå›ç­”
    response = generate_response(message, chunks, history)

    return response

# å»ºç«‹ Gradio ä»‹é¢
with gr.Blocks(title="å…¬å¸å®¢æœ AI åŠ©æ‰‹") as demo:
    gr.Markdown("# ğŸ¤– å…¬å¸å®¢æœ AI åŠ©æ‰‹")
    gr.Markdown("æˆ‘å¯ä»¥å¹«æ‚¨è§£ç­”é—œæ–¼å…¬å¸ç”¢å“ã€æœå‹™ã€æ”¿ç­–çš„å•é¡Œã€‚")

    chatbot = gr.Chatbot(height=500)
    msg = gr.Textbox(
        placeholder="è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...",
        label="æ‚¨çš„å•é¡Œ"
    )
    clear = gr.Button("æ¸…é™¤å°è©±")

    msg.submit(chatbot_interface, [msg, chatbot], [chatbot])
    clear.click(lambda: None, None, chatbot, queue=False)

demo.launch(share=True, debug=True)
```

---

## Agentic Search å·¥ä½œæµç¨‹

### ä½¿ç”¨è€…å•ï¼šã€Œå¦‚ä½•ç”³è«‹é€€æ¬¾ï¼Ÿã€

**æ¨™æº– RAG æµç¨‹ï¼š**
1. å°‡å•é¡Œè½‰æˆ embedding
2. FAISS æœå°‹æœ€ç›¸é—œçš„ 5 å€‹ chunks
3. æŠŠ chunks ä¸Ÿçµ¦ GPT-5 ç”Ÿæˆå›ç­”

**Agentic Search æµç¨‹ï¼š**
1. GPT-5 æ”¶åˆ°å•é¡Œ
2. GPT-5 æ±ºå®šï¼šã€Œæˆ‘éœ€è¦å…ˆçœ‹çœ‹æœ‰å“ªäº›è³‡æ–™ã€â†’ å‘¼å« `list_files`
3. ç³»çµ±å›å‚³ï¼š`["company_faq.md", "refund_policy.md", ...]`
4. GPT-5 æ±ºå®šï¼šã€Œé€€æ¬¾å•é¡Œæ‡‰è©²åœ¨ refund_policy.mdã€â†’ å‘¼å« `read_file("refund_policy.md")`
5. ç³»çµ±å›å‚³è©²æª”æ¡ˆçš„æ‰€æœ‰ chunks
6. GPT-5 å¾é€™äº› chunks ä¸­æ‰¾åˆ°ç­”æ¡ˆ
7. ç”Ÿæˆå›ç­”

**å„ªå‹¢ï¼š**
- ä½¿ç”¨è€…çœ‹åˆ° AI çš„æ€è€ƒéç¨‹
- æ›´ç²¾æº–åœ°å®šä½è³‡æ–™ä¾†æº
- å±•ç¤º AI çš„ä¸»å‹•æ€§

---

## ä½œæ¥­ç¹³äº¤è¦æ±‚

### Colab Notebook çµæ§‹

```python
# ====== Part A: å»ºç«‹å‘é‡è³‡æ–™åº« ======
# (å±•ç¤º build_vectordb.py çš„ç¨‹å¼ç¢¼å’Œèªªæ˜)
# è¨»æ˜ï¼šã€Œæ­¤éƒ¨åˆ†å·²åœ¨æœ¬åœ°åŸ·è¡Œå®Œæˆã€

# ====== Part B: RAG å°è©±æ©Ÿå™¨äºº ======

## 1. ç’°å¢ƒè¨­å®š
# å®‰è£å¥—ä»¶
!pip install openai faiss-cpu numpy gradio

## 2. ä¸‹è¼‰å‘é‡è³‡æ–™åº«
GDRIVE_URL = "https://drive.google.com/file/d/YOUR_ID/view?usp=sharing"
# ä¸‹è¼‰ä¸¦è§£å£“ç¸®

## 3. è¼‰å…¥å‘é‡è³‡æ–™åº«
# è¼‰å…¥ FAISS index å’Œ metadata

## 4. RAG ç³»çµ±
# å¯¦ä½œæª¢ç´¢å’Œç”ŸæˆåŠŸèƒ½

## 5. Gradio ä»‹é¢
# å•Ÿå‹•å°è©±æ©Ÿå™¨äºº
demo.launch(share=True)
```

### æˆªåœ–å…§å®¹

1. **è³‡æ–™èªªæ˜**ï¼šå±•ç¤ºä½¿ç”¨çš„ Q&A è³‡æ–™ï¼ˆqa_data/ æª”æ¡ˆæ¸…å–®ï¼‰
2. **äººè¨­è¨­å®š**ï¼šå±•ç¤º system prompt å’Œè§’è‰²è¨­å®š
3. **Gradio å°è©±çµæœ**ï¼š
   - è‡³å°‘ 3 å€‹å•ç­”ç¯„ä¾‹
   - å±•ç¤ºå›ç­”å“è³ª
   - ï¼ˆå¦‚æœæœ‰ agentic searchï¼‰å±•ç¤º AI æ€è€ƒéç¨‹

### Markdown èªªæ˜

```markdown
# Week 7 ä½œæ¥­ï¼šå…¬å¸å®¢æœ RAG å°è©±æ©Ÿå™¨äºº

## è³‡æ–™ä¾†æº
æˆ‘ä½¿ç”¨çš„è³‡æ–™æ˜¯...ï¼ˆèªªæ˜ä½ çš„ Q&A è³‡æ–™ï¼‰

## äººè¨­è¨­å®š
è§’è‰²ï¼šå°ˆæ¥­çš„å…¬å¸å®¢æœåŠ©æ‰‹
èªæ°£ï¼šè¦ªåˆ‡ã€æœ‰å¹«åŠ©
ç‰¹è‰²ï¼š...

## æŠ€è¡“æ¶æ§‹
- Part A: GPT-5 æ™ºèƒ½åˆ†å¡Š + FAISS å‘é‡è³‡æ–™åº«
- Part B: RAG æª¢ç´¢ + GPT-5 ç”Ÿæˆ + Gradio UI
- ï¼ˆå¯é¸ï¼‰Agentic Search: AI å¯ä»¥åˆ—å‡ºæª”æ¡ˆã€è®€å–æª”æ¡ˆ

## å°è©±ç¯„ä¾‹
ï¼ˆè²¼æˆªåœ–ï¼‰
```

---

## è©•åˆ†é‡é»

æ ¹æ“šä½œæ¥­è¦æ±‚ï¼š
- **6åˆ†**ï¼šä¸»é¡Œèˆ‡è€å¸«ç¯„ä¾‹ç›¸ä¼¼ï¼ˆæ ¡åœ’è¦å®šæŸ¥è©¢ï¼‰
- **7-9åˆ†**ï¼šæœ‰è¶£çš„ä¸»é¡Œ + å®Œæ•´åŠŸèƒ½
- **10åˆ†**ï¼šå®Œç¾ï¼æœ‰å‰µæ„ã€åŠŸèƒ½å®Œæ•´ã€å±•ç¤ºè‰¯å¥½

### åŠ åˆ†é …ç›®
- âœ… ä¸»é¡Œæœ‰è¶£ï¼ˆå…¬å¸å®¢æœæ¯”æ ¡è¦æœ‰è¶£ï¼‰
- âœ… Agentic search åŠŸèƒ½ï¼ˆå±•ç¤º AI æ€è€ƒéç¨‹ï¼‰
- âœ… å°è©±å“è³ªé«˜ï¼ˆå›ç­”æº–ç¢ºã€èªæ°£è‡ªç„¶ï¼‰
- âœ… UI ç¾è§€ï¼ˆGradio å®¢è£½åŒ–ï¼‰
- âœ… èªªæ˜æ¸…æ¥šï¼ˆMarkdown + æˆªåœ–ï¼‰

---

## é–‹ç™¼å»ºè­°

### å„ªå…ˆé †åº

**ç¬¬ä¸€éšæ®µï¼ˆåŸºæœ¬åŠŸèƒ½ï¼‰ï¼š**
1. è¼‰å…¥ FAISS å‘é‡è³‡æ–™åº«
2. å¯¦ä½œåŸºæœ¬ RAGï¼ˆæª¢ç´¢ + ç”Ÿæˆï¼‰
3. Gradio åŸºæœ¬ä»‹é¢
4. æ¸¬è©¦ 3-5 å€‹å•ç­”

**ç¬¬äºŒéšæ®µï¼ˆé€²éšåŠŸèƒ½ï¼‰ï¼š**
1. åŠ å…¥ agentic search tools
2. å±•ç¤º AI æ€è€ƒéç¨‹
3. ç¾åŒ– Gradio UI
4. æº–å‚™æˆªåœ–å’Œèªªæ˜

### æ¸¬è©¦å»ºè­°

**æœ¬åœ°æ¸¬è©¦ï¼š**
```bash
cd Week7
uv run python rag_chatbot.py
```

**Colab æ¸¬è©¦ï¼š**
- ç¢ºä¿ Google Drive é€£çµå¯ä¸‹è¼‰
- æ¸¬è©¦ API key è®€å–
- æ¸¬è©¦ Gradio share link

---

## åƒè€ƒè³‡æ–™

### è€å¸«ç¯„ä¾‹

1. **Demo06a**ï¼šå»ºç«‹å‘é‡è³‡æ–™åº«ï¼ˆå·²å®Œæˆ Part Aï¼‰
2. **Demo06b**ï¼šRAG ç³»çµ±
   - ä½¿ç”¨ LangChain
   - Groq API
   - æ”¿å¤§è¦å®šæŸ¥è©¢

3. **Demo06**ï¼šå¿ƒéˆè™•æ–¹ç±¤æ©Ÿå™¨äºº
   - éš¨æ©ŸæŠ½ç±¤åŠŸèƒ½
   - çµåˆæ›¸ç±å…§å®¹
   - æº«å’Œçš„å›ç­”é¢¨æ ¼

### æŠ€è¡“æ–‡ä»¶

- OpenAI Response APIï¼š`response API OpenAI GPT 5/`
- GPT-5 tool callingï¼š`function calling.md`
- Text generationï¼š`text generation.md`

---

## é‡è¦æé†’

1. **å¿…é ˆåŒ…å«è€å¸«çš„å›ºå®šå¥—ä»¶**
   - LangChainï¼ˆæˆ–é¡ä¼¼çš„ RAG æ¡†æ¶ï¼‰
   - FAISS
   - Gradio
   - ç¼ºä¸€æ‰£ 1 åˆ†ï¼

2. **Colab æ¬Šé™**
   - ã€ŒçŸ¥é“é€£çµçš„ä»»ä½•äººã€å¯æª¢è¦–
   - Google Drive é€£çµè¦èƒ½ä¸‹è¼‰

3. **AI å”åŠ©èªªæ˜**
   - å¦‚æœç”¨ AI å¹«å¿™ï¼Œè¦èªªæ˜å“ªè£¡ç”¨äº†
   - é™„ä¸Š Prompt å’Œçµæœæˆªåœ–
   - åŠ ä¸Šè‡ªå·±çš„ç†è§£èªªæ˜

4. **æˆªæ­¢æ™‚é–“**
   - 10/27 23:59ï¼ˆä»Šå¤©ï¼ï¼‰
   - é²äº¤æœŸé™ï¼š10/28 23:59

---

## ä¸‹ä¸€æ­¥è¡Œå‹•

1. âœ… é–±è®€æœ¬æ–‡ä»¶
2. â¬œ å¯¦ä½œ `rag_chatbot.py`
3. â¬œ æ¸¬è©¦æœ¬åœ°åŸ·è¡Œ
4. â¬œ æº–å‚™ Colab notebook
5. â¬œ ä¸Šå‚³ faiss_db.zip åˆ° Google Drive
6. â¬œ æ¸¬è©¦ Colab åŸ·è¡Œ
7. â¬œ æˆªåœ–å’Œèªªæ˜
8. â¬œ ç¹³äº¤ä½œæ¥­

**ç¥é–‹ç™¼é †åˆ©ï¼ğŸš€**
